x-templates:
  vllm: &vllm
    build:
      context: .
      dockerfile: Dockerfile.vllm
    container_name: openai-endpoint
    restart: unless-stopped
    ports:
      - "30000:30000"
    environment:
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - VLLM_NO_USAGE_STATS=1
      - DO_NOT_TRACK=1
    volumes:
      - ./serve.vllm.sh:/serve.sh
    init: true
    entrypoint: ["/bin/bash", "-c"]
    command: ["/serve.sh"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  sglang: &sglang
    build:
      context: .
      dockerfile: Dockerfile.sglang
    container_name: openai-endpoint
    restart: unless-stopped
    ports:
      - "30000:30000"
    volumes:
      - ./serve.sglang.sh:/serve.sh
    init: true
    entrypoint: ["/bin/bash", "-c"]
    command: ["/serve.sh"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

services:  
  openai-endpoint: *vllm # *sglang

  nvidia_gpu_exporter:
    image: nvidia/dcgm-exporter:latest
    container_name: exporter
    restart: unless-stopped
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "9400:9400"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus

  haproxy:
    image: haproxy:latest
    container_name: haproxy
    restart: unless-stopped
    ports:
      - "8080:80"
    volumes:
      - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg
    depends_on:
      - openai-endpoint

volumes:
  prometheus_data:
  grafana_data:
